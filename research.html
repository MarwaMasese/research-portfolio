<!DOCTYPE html><!--yjXxMsqJOp5DUA3l48t11--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/research-portfolio/_next/static/css/624db82297857320.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/research-portfolio/_next/static/chunks/webpack-abad5f0f82352a38.js"/><script src="/research-portfolio/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/research-portfolio/_next/static/chunks/255-e2191d15019aae75.js" async=""></script><script src="/research-portfolio/_next/static/chunks/main-app-e1d4411bd2cc7f8b.js" async=""></script><script src="/research-portfolio/_next/static/chunks/619-ba102abea3e3d0e4.js" async=""></script><script src="/research-portfolio/_next/static/chunks/app/layout-c73ec5bf13e80c87.js" async=""></script><title>Cornelius Maroa Portfolio</title><meta name="description" content="AI Researcher &amp; CTO specializing in Audio AI and Conversational Systems"/><link rel="icon" href="/profile.jpg"/><script src="/research-portfolio/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_5c0c59 __variable_f968f8 antialiased"><div hidden=""><!--$--><!--/$--></div><nav class="w-full bg-white border-b border-gray-200 py-4"><div class="max-w-7xl mx-auto px-6"><div class="flex justify-center space-x-12"><a class="text-lg font-medium transition-colors hover:text-gray-600 text-gray-500" href="/research-portfolio">Home</a><a class="text-lg font-medium transition-colors hover:text-gray-600 text-gray-500" href="/research-portfolio/updates">Updates</a><a class="text-lg font-medium transition-colors hover:text-gray-600 text-gray-900 border-b-2 border-gray-900 pb-1" href="/research-portfolio/research">Research</a><a class="text-lg font-medium transition-colors hover:text-gray-600 text-gray-500" href="/research-portfolio/teaching">Teaching &amp; Talks</a><a class="text-lg font-medium transition-colors hover:text-gray-600 text-blue-600" href="/research-portfolio/contact">Contact</a></div></div></nav><main class="min-h-screen"><div class="min-h-screen bg-white"><div class="max-w-6xl mx-auto px-6 py-16"><h1 class="text-4xl font-light text-gray-900 mb-12 text-center">Research</h1><section class="mb-16"><h2 class="text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2">Featured Research Projects</h2><div class="space-y-12"><div class="bg-gray-50 border rounded-lg p-8"><div class="flex items-start justify-between mb-4"><h3 class="text-2xl font-medium text-gray-900 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="mr-3 text-blue-600" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505.12019,19.09375c-1.18945-5.53125-6.65819-11-12.207-12.1875C460.716,0,435.507,0,410.40747,0,307.17523,0,245.26909,55.20312,199.05238,128H94.83772c-16.34763.01562-35.55658,11.875-42.88664,26.48438L2.51562,253.29688A28.4,28.4,0,0,0,0,264a24.00867,24.00867,0,0,0,24.00582,24H127.81618l-22.47457,22.46875c-11.36521,11.36133-12.99607,32.25781,0,45.25L156.24582,406.625c11.15623,11.1875,32.15619,13.15625,45.27726,0l22.47457-22.46875V488a24.00867,24.00867,0,0,0,24.00581,24,28.55934,28.55934,0,0,0,10.707-2.51562l98.72834-49.39063c14.62888-7.29687,26.50776-26.5,26.50776-42.85937V312.79688c72.59753-46.3125,128.03493-108.40626,128.03493-211.09376C512.07526,76.5,512.07526,51.29688,505.12019,19.09375ZM384.04033,168A40,40,0,1,1,424.05,128,40.02322,40.02322,0,0,1,384.04033,168Z"></path></svg>Vociply: Real-Time Voice AI System</h3><div class="text-right text-sm"><div class="text-green-600 font-medium">Active Research &amp; Development</div><div class="text-gray-500">Deep Learning Indaba 2025</div></div></div><p class="text-gray-700 mb-6 leading-relaxed text-lg">A groundbreaking voice-to-voice agentic system that combines large language models with real-time speech processing to automate business conversations in multiple African languages.</p><div class="mb-6 flex gap-4 flex-wrap"><a href="https://openreview.net/forum?id=RiJUdKWD3u&amp;noteId=RiJUdKWD3u" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg> Paper</a><a href="https://deeplearningindaba.com/2025/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 bg-green-600 text-white px-4 py-2 rounded-lg hover:bg-green-700 transition-colors"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z"></path></svg> Conference</a></div><div class="grid md:grid-cols-2 gap-6"><div><h4 class="font-medium text-gray-900 mb-3">Research Contributions:</h4><ul class="list-disc list-inside text-gray-600 space-y-1"><li>Novel architecture bridging LLMs with speech processing</li><li>Creative solutions for multilingual data scarcity</li><li>Real-time optimization for voice-based AI agents</li><li>Production-scale deployment of research prototypes</li></ul></div><div><h4 class="font-medium text-gray-900 mb-3">Technical Highlights:</h4><ul class="list-disc list-inside text-gray-600 space-y-1"><li>End-to-end voice processing pipeline</li><li>Multilingual natural language understanding</li><li>Real-time response generation (&lt;200ms latency)</li><li>Scalable cloud infrastructure</li></ul></div></div></div><div class="bg-gray-50 border rounded-lg p-8"><div class="flex items-start justify-between mb-4"><h3 class="text-2xl font-medium text-gray-900 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" class="mr-3 text-green-600" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M208 0c-29.9 0-54.7 20.5-61.8 48.2-.8 0-1.4-.2-2.2-.2-35.3 0-64 28.7-64 64 0 4.8.6 9.5 1.7 14C52.5 138 32 166.6 32 200c0 12.6 3.2 24.3 8.3 34.9C16.3 248.7 0 274.3 0 304c0 33.3 20.4 61.9 49.4 73.9-.9 4.6-1.4 9.3-1.4 14.1 0 39.8 32.2 72 72 72 4.1 0 8.1-.5 12-1.2 9.6 28.5 36.2 49.2 68 49.2 39.8 0 72-32.2 72-72V64c0-35.3-28.7-64-64-64zm368 304c0-29.7-16.3-55.3-40.3-69.1 5.2-10.6 8.3-22.3 8.3-34.9 0-33.4-20.5-62-49.7-74 1-4.5 1.7-9.2 1.7-14 0-35.3-28.7-64-64-64-.8 0-1.5.2-2.2.2C422.7 20.5 397.9 0 368 0c-35.3 0-64 28.6-64 64v376c0 39.8 32.2 72 72 72 31.8 0 58.4-20.7 68-49.2 3.9.7 7.9 1.2 12 1.2 39.8 0 72-32.2 72-72 0-4.8-.5-9.5-1.4-14.1 29-12 49.4-40.6 49.4-73.9z"></path></svg>Hypernetwork Optimization Framework</h3><div class="text-right text-sm"><div class="text-green-600 font-medium">Research Draft</div><div class="text-gray-500">Target: Top-tier AI Conference</div></div></div><p class="text-gray-700 mb-6 leading-relaxed text-lg">Investigating how hypernetworks can optimize ternary neural networks for efficient edge AI deployment, addressing the critical need for AI democratization in resource-constrained environments.</p><div class="grid md:grid-cols-2 gap-6"><div><h4 class="font-medium text-gray-900 mb-3">Research Contributions:</h4><ul class="list-disc list-inside text-gray-600 space-y-1"><li>Can hypernetworks improve ternary network training efficiency?</li><li>What are the optimal architectures for edge AI deployment?</li><li>How can we balance accuracy with computational constraints?</li></ul></div><div><h4 class="font-medium text-gray-900 mb-3">Technical Highlights:</h4><ul class="list-disc list-inside text-gray-600 space-y-1"><li>More efficient AI models for mobile and IoT devices</li><li>Reduced computational requirements for AI applications</li><li>Broader accessibility of advanced AI technologies</li></ul></div></div></div><div class="bg-gray-50 border rounded-lg p-8"><div class="flex items-start justify-between mb-4"><h3 class="text-2xl font-medium text-gray-900 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="mr-3 text-purple-600" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"></path></svg>Multilingual Voice AI Research</h3><div class="text-right text-sm"><div class="text-green-600 font-medium">Ongoing</div><div class="text-gray-500">Collaboration: Vociply Research Lab</div></div></div><p class="text-gray-700 mb-6 leading-relaxed text-lg">Pioneering research in voice AI systems that work effectively across African languages, addressing fundamental challenges in low-resource language processing.</p><div class="grid md:grid-cols-2 gap-6"><div><h4 class="font-medium text-gray-900 mb-3">Research Contributions:</h4><ul class="list-disc list-inside text-gray-600 space-y-1"><li>Data augmentation for speech data scarcity</li><li>Transfer learning across related languages</li><li>Cultural and linguistic adaptation in AI systems</li><li>Community-driven dataset development</li></ul></div></div></div></div></section><section class="mb-16"><h2 class="text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2">Conference Participation</h2><div class="grid md:grid-cols-2 gap-6"><div class="bg-white border rounded-lg p-6 shadow-sm"><h3 class="text-lg font-medium text-gray-900 mb-2"><a href="https://deeplearningindaba.com/2025/" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 flex items-center gap-2">Deep Learning Indaba 2025<!-- --> <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-sm" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z"></path></svg></a></h3><p class="text-gray-600 text-sm">Africa<!-- --> • <!-- -->2025</p></div><div class="bg-white border rounded-lg p-6 shadow-sm"><h3 class="text-lg font-medium text-gray-900 mb-2"><a href="https://appliedmldays.org/events/amld-africa-2024" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:text-blue-800 flex items-center gap-2">AMLD Africa 2024<!-- --> <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="text-sm" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z"></path></svg></a></h3><p class="text-gray-600 text-sm">USIU Kenya<!-- --> • <!-- -->2024</p></div></div></section><section class="mb-16"><h2 class="text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2">Publications &amp; Academic Output</h2><div class="space-y-6"><div class="border-l-4 border-blue-200 pl-6 py-4"><div class="flex items-start justify-between mb-2"><h3 class="text-lg font-medium text-gray-900">Vociply: A Real-Time Voice-to-Voice Agentic System for African Business Automation Using LLMs</h3><div class="text-sm text-gray-500">2025</div></div><p class="text-gray-600 mb-1">Maroa, C. et al.</p><div class="flex items-center gap-4"><p class="text-blue-600 text-sm">Deep Learning Indaba 2025<!-- --> <!-- -->[Accepted]</p><a href="https://openreview.net/forum?id=RiJUdKWD3u&amp;noteId=RiJUdKWD3u" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1 text-blue-600 hover:text-blue-800 text-sm"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z"></path></svg> View Paper</a></div></div><div class="border-l-4 border-blue-200 pl-6 py-4"><div class="flex items-start justify-between mb-2"><h3 class="text-lg font-medium text-gray-900">Hypernetwork Optimization of Ternary Neural Networks for Edge AI Deployment</h3><div class="text-sm text-gray-500">In Progress</div></div><p class="text-gray-600 mb-1">Maroa, C. et al.</p><div class="flex items-center gap-4"><p class="text-blue-600 text-sm">Research Draft<!-- --> <!-- -->[Draft]</p></div></div></div><div class="mt-8 p-6 bg-blue-50 rounded-lg"><h3 class="font-medium text-gray-900 mb-3">Research Pipeline</h3><ul class="list-disc list-inside text-gray-700 space-y-1"><li>Edge AI democratization tools and methodologies</li><li>Multilingual conversational AI architectures</li><li>Audio processing optimization techniques</li><li>Human-AI interaction paradigm studies</li></ul></div></section><section><h2 class="text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2">Open Source Contributions</h2><div class="grid md:grid-cols-2 gap-8"><div class="bg-white border rounded-lg p-6 shadow-sm"><h3 class="text-xl font-medium text-gray-900 mb-2 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="mr-2 text-blue-600" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M501.1 395.7L384 278.6c-23.1-23.1-57.6-27.6-85.4-13.9L192 158.1V96L64 0 0 64l96 128h62.1l106.6 106.6c-13.6 27.8-9.2 62.3 13.9 85.4l117.1 117.1c14.6 14.6 38.2 14.6 52.7 0l52.7-52.7c14.5-14.6 14.5-38.2 0-52.7zM331.7 225c28.3 0 54.9 11 74.9 31l19.4 19.4c15.8-6.9 30.8-16.5 43.8-29.5 37.1-37.1 49.7-89.3 37.9-136.7-2.2-9-13.5-12.1-20.1-5.5l-74.4 74.4-67.9-11.3L334 98.9l74.4-74.4c6.6-6.6 3.4-17.9-5.7-20.2-47.4-11.7-99.6.9-136.6 37.9-28.5 28.5-41.9 66.1-41.2 103.6l82.1 82.1c8.1-1.9 16.5-2.9 24.7-2.9zm-103.9 82l-56.7-56.7L18.7 402.8c-25 25-25 65.5 0 90.5s65.5 25 90.5 0l123.6-123.6c-7.6-19.9-9.9-41.6-5-62.7zM64 472c-13.2 0-24-10.8-24-24 0-13.3 10.7-24 24-24s24 10.7 24 24c0 13.2-10.7 24-24 24z"></path></svg>Edge AI Optimization Tools</h3><div class="text-sm text-gray-500 mb-4">Available on GitHub<!-- --> | <!-- -->500+ developers</div><p class="text-gray-700 mb-4 leading-relaxed">Open-source utilities for deploying efficient ML models on ARM-based devices, democratizing AI deployment capabilities.</p><div><h4 class="font-medium text-gray-900 mb-2">Features:</h4><ul class="list-disc list-inside text-gray-600 space-y-1 text-sm"><li>Model compression utilities</li><li>Performance benchmarking tools</li><li>Deployment automation scripts</li><li>Educational resources and tutorials</li></ul></div></div><div class="bg-white border rounded-lg p-6 shadow-sm"><h3 class="text-xl font-medium text-gray-900 mb-2 flex items-center"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" class="mr-2 text-green-600" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm64 236c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12v8zm0-64c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12v8zm0-72v8c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12zm96-114.1v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z"></path></svg>AI Learning Resources</h3><div class="text-sm text-gray-500 mb-4">ARM Ambassador Program<!-- --> | <!-- -->1000+ learners</div><p class="text-gray-700 mb-4 leading-relaxed">Comprehensive learning paths and documentation bridging academic ML research with practical implementation.</p><div><h4 class="font-medium text-gray-900 mb-2">Features:</h4><ul class="list-disc list-inside text-gray-600 space-y-1 text-sm"><li>Workshop materials and tutorials</li><li>Code examples and best practices</li><li>Mentorship programs for emerging researchers</li><li>Technical documentation and guides</li></ul></div></div></div></section></div></div><!--$--><!--/$--></main><script src="/research-portfolio/_next/static/chunks/webpack-abad5f0f82352a38.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3655,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"177\",\"static/chunks/app/layout-c73ec5bf13e80c87.js\"],\"default\"]\n3:I[9766,[],\"\"]\n4:I[8924,[],\"\"]\nf:I[7150,[],\"\"]\n:HL[\"/research-portfolio/_next/static/css/624db82297857320.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"yjXxMsqJOp5DUA3l48t11\",\"p\":\"/research-portfolio\",\"c\":[\"\",\"research\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"research\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/research-portfolio/_next/static/css/624db82297857320.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_5c0c59 __variable_f968f8 antialiased\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]}]]}],{\"children\":[\"research\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto px-6 py-16\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-light text-gray-900 mb-12 text-center\",\"children\":\"Research\"}],[\"$\",\"section\",null,{\"className\":\"mb-16\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2\",\"children\":\"Featured Research Projects\"}],[\"$\",\"div\",null,{\"className\":\"space-y-12\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-gray-50 border rounded-lg p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between mb-4\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-medium text-gray-900 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"mr-3 text-blue-600\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M505.12019,19.09375c-1.18945-5.53125-6.65819-11-12.207-12.1875C460.716,0,435.507,0,410.40747,0,307.17523,0,245.26909,55.20312,199.05238,128H94.83772c-16.34763.01562-35.55658,11.875-42.88664,26.48438L2.51562,253.29688A28.4,28.4,0,0,0,0,264a24.00867,24.00867,0,0,0,24.00582,24H127.81618l-22.47457,22.46875c-11.36521,11.36133-12.99607,32.25781,0,45.25L156.24582,406.625c11.15623,11.1875,32.15619,13.15625,45.27726,0l22.47457-22.46875V488a24.00867,24.00867,0,0,0,24.00581,24,28.55934,28.55934,0,0,0,10.707-2.51562l98.72834-49.39063c14.62888-7.29687,26.50776-26.5,26.50776-42.85937V312.79688c72.59753-46.3125,128.03493-108.40626,128.03493-211.09376C512.07526,76.5,512.07526,51.29688,505.12019,19.09375ZM384.04033,168A40,40,0,1,1,424.05,128,40.02322,40.02322,0,0,1,384.04033,168Z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\"Vociply: Real-Time Voice AI System\"]}],[\"$\",\"div\",null,{\"className\":\"text-right text-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-green-600 font-medium\",\"children\":\"Active Research \u0026 Development\"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500\",\"children\":\"Deep Learning Indaba 2025\"}]]}]]}],\"$L5\",\"$L6\",\"$L7\"]}],\"$L8\",\"$L9\"]}]]}],\"$La\",\"$Lb\",\"$Lc\"]}]}],null,\"$Ld\"]}],{},null,false]},null,false]},null,false],\"$Le\",false]],\"m\":\"$undefined\",\"G\":[\"$f\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:I[4431,[],\"OutletBoundary\"]\n13:I[5278,[],\"AsyncMetadataOutlet\"]\n15:I[4431,[],\"ViewportBoundary\"]\n17:I[4431,[],\"MetadataBoundary\"]\n18:\"$Sreact.suspense\"\n5:[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-6 leading-relaxed text-lg\",\"children\":\"A groundbreaking voice-to-voice agentic system that combines large language models with real-time speech processing to automate business conversations in multiple African languages.\"}]\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"div\",null,{\"className\":\"mb-6 flex gap-4 flex-wrap\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://openreview.net/forum?id=RiJUdKWD3u\u0026noteId=RiJUdKWD3u\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-2 bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 384 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\" Paper\"]}],[\"$\",\"a\",null,{\"href\":\"https://deeplearningindaba.com/2025/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-2 bg-green-600 text-white px-4 py-2 rounded-lg hover:bg-green-700 transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\" Conference\"]}]]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"grid md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Research Contributions:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"Novel architecture bridging LLMs with speech processing\"}],[\"$\",\"li\",\"1\",{\"children\":\"Creative solutions for multilingual data scarcity\"}],[\"$\",\"li\",\"2\",{\"children\":\"Real-time optimization for voice-based AI agents\"}],[\"$\",\"li\",\"3\",{\"children\":\"Production-scale deployment of research prototypes\"}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Technical Highlights:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"End-to-end voice processing pipeline\"}],[\"$\",\"li\",\"1\",{\"children\":\"Multilingual natural language understanding\"}],[\"$\",\"li\",\"2\",{\"children\":\"Real-time response generation (\u003c200ms latency)\"}],[\"$\",\"li\",\"3\",{\"children\":\"Scalable cloud infrastructure\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",\"1\",{\"className\":\"bg-gray-50 border rounded-lg p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between mb-4\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-medium text-gray-900 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 576 512\",\"className\":\"mr-3 text-green-600\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M208 0c-29.9 0-54.7 20.5-61.8 48.2-.8 0-1.4-.2-2.2-.2-35.3 0-64 28.7-64 64 0 4.8.6 9.5 1.7 14C52.5 138 32 166.6 32 200c0 12.6 3.2 24.3 8.3 34.9C16.3 248.7 0 274.3 0 304c0 33.3 20.4 61.9 49.4 73.9-.9 4.6-1.4 9.3-1.4 14.1 0 39.8 32.2 72 72 72 4.1 0 8.1-.5 12-1.2 9.6 28.5 36.2 49.2 68 49.2 39.8 0 72-32.2 72-72V64c0-35.3-28.7-64-64-64zm368 304c0-29.7-16.3-55.3-40.3-69.1 5.2-10.6 8.3-22.3 8.3-34.9 0-33.4-20.5-62-49.7-74 1-4.5 1.7-9.2 1.7-14 0-35.3-28.7-64-64-64-.8 0-1.5.2-2.2.2C422.7 20.5 397.9 0 368 0c-35.3 0-64 28.6-64 64v376c0 39.8 32.2 72 72 72 31.8 0 58.4-20.7 68-49.2 3.9.7 7.9 1.2 12 1.2 39.8 0 72-32.2 72-72 0-4.8-.5-9.5-1.4-14.1 29-12 49.4-40.6 49.4-73.9z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\"Hypernetwork Optimization Framework\"]}],[\"$\",\"div\",null,{\"className\":\"text-right text-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-green-600 font-medium\",\"children\":\"Research Draft\"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500\",\"children\":\"Target: Top-tier AI Conference\"}]]}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-6 leading-relaxed text-lg\",\"children\":\"Investigating how hypernetworks can optimize ternary neural networks for efficient edge AI deployment, addressing the critical need for AI democratization in resource-constrained environments.\"}],\"$undefined\",[\"$\",\"div\",null,{\"className\":\"grid md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Research Contributions:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"Can hypernetworks improve ternary network training efficiency?\"}],[\"$\",\"li\",\"1\",{\"children\":\"What are the optimal architectures for edge AI deployment?\"}],[\"$\",\"li\",\"2\",{\"children\":\"How can we balance accuracy with computational constraints?\"}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Technical Highlights:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"More efficient AI models for mobile and IoT devices\"}],[\"$\",\"li\",\"1\",{\"children\":\"Reduced computational requirements for AI applications\"}],[\"$\",\"li\",\"2\",{\"children\":\"Broader accessibility of advanced AI technologies\"}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"div\",\"2\",{\"className\":\"bg-gray-50 border rounded-lg p-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between mb-4\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-medium text-gray-900 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 496 512\",\"className\":\"mr-3 text-purple-600\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\"Multilingual Voice AI Research\"]}],[\"$\",\"div\",null,{\"className\":\"text-right text-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-green-600 font-medium\",\"children\":\"Ongoing\"}],[\"$\",\"div\",null,{\"className\":\"text-gray-500\",\"children\":\"Collaboration: Vociply Research Lab\"}]]}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-6 leading-relaxed text-lg\",\"children\":\"Pioneering research in voice AI systems that work effectively across African languages, addressing fundamental challenges in low-resource language processing.\"}],\"$undefined\",[\"$\",\"div\",null,{\"className\":\"grid md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Research Contributions:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"Data augmentation for speech data scarcity\"}],[\"$\",\"li\",\"1\",{\"children\":\"Transfer learning across related languages\"}],[\"$\",\"li\",\"2\",{\"children\":\"Cultural and linguistic adaptation in AI systems\"}],[\"$\",\"li\",\"3\",{\"children\":\"Community-driven dataset development\"}]]}]]}],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"section\",null,{\"className\":\"mb-16\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2\",\"children\":\"Conference Participation\"}],[\"$\",\"div\",null,{\"className\":\"grid md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-white border rounded-lg p-6 shadow-sm\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-medium text-gray-900 mb-2\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://deeplearningindaba.com/2025/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 flex items-center gap-2\",\"children\":[\"Deep Learning Indaba 2025\",\" \",[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"text-sm\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]]}]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-sm\",\"children\":[\"Africa\",\" • \",\"2025\"]}]]}],[\"$\",\"div\",\"1\",{\"className\":\"bg-white border rounded-lg p-6 shadow-sm\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-medium text-gray-900 mb-2\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://appliedmldays.org/events/amld-africa-2024\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-600 hover:text-blue-800 flex items-center gap-2\",\"children\":[\"AMLD Africa 2024\",\" \",[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"text-sm\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}]]}]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-sm\",\"children\":[\"USIU Kenya\",\" • \",\"2024\"]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"section\",null,{\"className\":\"mb-16\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2\",\"children\":\"Publications \u0026 Academic Output\"}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"border-l-4 border-blue-200 pl-6 py-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between mb-2\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-medium text-gray-900\",\"children\":\"Vociply: A Real-Time Voice-to-Voice Agentic System for African Business Automation Using LLMs\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-500\",\"children\":\"2025\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-1\",\"children\":\"Maroa, C. et al.\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-blue-600 text-sm\",\"children\":[\"Deep Learning Indaba 2025\",\" \",\"[Accepted]\"]}],[\"$\",\"a\",null,{\"href\":\"https://openreview.net/forum?id=RiJUdKWD3u\u0026noteId=RiJUdKWD3u\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1 text-blue-600 hover:text-blue-800 text-sm\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\" View Paper\"]}]]}]]}],[\"$\",\"div\",\"1\",{\"className\":\"border-l-4 border-blue-200 pl-6 py-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between mb-2\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-medium text-gray-900\",\"children\":\"Hypernetwork Optimization of Ternary Neural Networks for Edge AI Deployment\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-500\",\"children\":\"In Progress\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-1\",\"children\":\"Maroa, C. et al.\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-blue-600 text-sm\",\"children\":[\"Research Draft\",\" \",\"[Draft]\"]}],null]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 p-6 bg-blue-50 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium text-gray-900 mb-3\",\"children\":\"Research Pipeline\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-700 space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Edge AI democratization tools and methodologies\"}],[\"$\",\"li\",null,{\"children\":\"Multilingual conversational AI architectures\"}],[\"$\",\"li\",null,{\"children\":\"Audio processing optimization techniques\"}],[\"$\",\"li\",null,{\"children\":\"Human-AI interaction paradigm studies\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"section\",null,{\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-light text-gray-900 mb-8 border-b border-gray-200 pb-2\",\"children\":\"Open Source Contributions\"}],[\"$\",\"div\",null,{\"className\":\"grid md:grid-cols-2 gap-8\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-white border rounded-lg p-6 shadow-sm\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-medium text-gray-900 mb-2 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"className\":\"mr-2 text-blue-600\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M501.1 395.7L384 278.6c-23.1-23.1-57.6-27.6-85.4-13.9L192 158.1V96L64 0 0 64l96 128h62.1l106.6 106.6c-13.6 27.8-9.2 62.3 13.9 85.4l117.1 117.1c14.6 14.6 38.2 14.6 52.7 0l52.7-52.7c14.5-14.6 14.5-38.2 0-52.7zM331.7 225c28.3 0 54.9 11 74.9 31l19.4 19.4c15.8-6.9 30.8-16.5 43.8-29.5 37.1-37.1 49.7-89.3 37.9-136.7-2.2-9-13.5-12.1-20.1-5.5l-74.4 74.4-67.9-11.3L334 98.9l74.4-74.4c6.6-6.6 3.4-17.9-5.7-20.2-47.4-11.7-99.6.9-136.6 37.9-28.5 28.5-41.9 66.1-41.2 103.6l82.1 82.1c8.1-1.9 16.5-2.9 24.7-2.9zm-103.9 82l-56.7-56.7L18.7 402.8c-25 25-25 65.5 0 90.5s65.5 25 90.5 0l123.6-123.6c-7.6-19.9-9.9-41.6-5-62.7zM64 472c-13.2 0-24-10.8-24-24 0-13.3 10.7-24 24-24s24 10.7 24 24c0 13.2-10.7 24-24 24z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\"Edge AI Optimization Tools\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"Available on GitHub\",\" | \",\"500+ developers\"]}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-4 leading-relaxed\",\"children\":\"Open-source utilities for deploying efficient ML models on ARM-based devices, democratizing AI deployment capabilities.\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Features:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1 text-sm\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"Model compression utilities\"}],[\"$\",\"li\",\"1\",{\"children\":\"Performance benchmarking tools\"}],[\"$\",\"li\",\"2\",{\"children\":\"Deployment automation scripts\"}],[\"$\",\"li\",\"3\",{\"children\":\"Educational resources and tutorials\"}]]}]]}]]}],[\"$\",\"div\",\"1\",{\"className\":\"bg-white border rounded-lg p-6 shadow-sm\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xl font-medium text-gray-900 mb-2 flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 384 512\",\"className\":\"mr-2 text-green-600\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm64 236c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12v8zm0-64c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12v8zm0-72v8c0 6.6-5.4 12-12 12H108c-6.6 0-12-5.4-12-12v-8c0-6.6 5.4-12 12-12h168c6.6 0 12 5.4 12 12zm96-114.1v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],\"AI Learning Resources\"]}],[\"$\",\"div\",null,{\"className\":\"text-sm text-gray-500 mb-4\",\"children\":[\"ARM Ambassador Program\",\" | \",\"1000+ learners\"]}],[\"$\",\"p\",null,{\"className\":\"text-gray-700 mb-4 leading-relaxed\",\"children\":\"Comprehensive learning paths and documentation bridging academic ML research with practical implementation.\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-medium text-gray-900 mb-2\",\"children\":\"Features:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside text-gray-600 space-y-1 text-sm\",\"children\":[[\"$\",\"li\",\"0\",{\"children\":\"Workshop materials and tutorials\"}],[\"$\",\"li\",\"1\",{\"children\":\"Code examples and best practices\"}],[\"$\",\"li\",\"2\",{\"children\":\"Mentorship programs for emerging researchers\"}],\"$L10\"]}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"$L11\",null,{\"children\":[\"$L12\",[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]]}]\ne:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L15\",null,{\"children\":\"$L16\"}],null],[\"$\",\"$L17\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$18\",null,{\"fallback\":null,\"children\":\"$L19\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"10:[\"$\",\"li\",\"3\",{\"children\":\"Technical documentation and guides\"}]\n"])</script><script>self.__next_f.push([1,"16:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n12:null\n"])</script><script>self.__next_f.push([1,"1a:I[622,[],\"IconMark\"]\n14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Cornelius Maroa Portfolio\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"AI Researcher \u0026 CTO specializing in Audio AI and Conversational Systems\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/profile.jpg\"}],[\"$\",\"$L1a\",\"3\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"19:\"$14:metadata\"\n"])</script></body></html>